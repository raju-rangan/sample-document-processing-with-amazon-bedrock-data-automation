#!/bin/bash

# Integration Test Script for Document Processing System
# This script tests the complete workflow from document upload to webhook call

set -e

echo "ğŸ§ª Starting Integration Test for Document Processing System"

# Check if we're in the right directory
if [ ! -f "terraform/main.tf" ]; then
    echo "âŒ Error: Please run this script from the project root directory"
    exit 1
fi

# Check if Terraform is initialized
if [ ! -d "terraform/.terraform" ]; then
    echo "âŒ Error: Terraform not initialized. Run 'terraform init' first"
    exit 1
fi

# Get Terraform outputs
echo "ğŸ“‹ Getting Terraform outputs..."
cd terraform

BUCKET_NAME=$(terraform output -raw document_bucket_name 2>/dev/null || echo "")
LAMBDA_FUNCTION=$(terraform output -raw lambda_function_name 2>/dev/null || echo "")
KB_ID=$(terraform output -raw knowledge_base_id 2>/dev/null || echo "")

if [ -z "$BUCKET_NAME" ] || [ -z "$LAMBDA_FUNCTION" ] || [ -z "$KB_ID" ]; then
    echo "âŒ Error: Could not retrieve Terraform outputs. Make sure infrastructure is deployed."
    exit 1
fi

echo "âœ… Retrieved infrastructure details:"
echo "   - Document Bucket: $BUCKET_NAME"
echo "   - Lambda Function: $LAMBDA_FUNCTION"
echo "   - Knowledge Base ID: $KB_ID"

cd ..

# Create test document
echo "ğŸ“„ Creating test document..."
TEST_FILE="test-document-$(date +%s).txt"
cat > "$TEST_FILE" << EOF
Test Document for Integration Testing
=====================================

This is a test document created on $(date).

Content:
- Document processing system test
- Amazon Bedrock Knowledge Base integration
- EventBridge and Lambda function testing
- S3 storage and retrieval validation

Keywords: test, document, processing, bedrock, lambda, s3
EOF

echo "âœ… Created test document: $TEST_FILE"

# Upload test document
echo "ğŸ“¤ Uploading test document to S3..."
aws s3 cp "$TEST_FILE" "s3://$BUCKET_NAME/" || {
    echo "âŒ Error: Failed to upload test document to S3"
    rm -f "$TEST_FILE"
    exit 1
}

echo "âœ… Successfully uploaded test document"

# Wait for processing
echo "â³ Waiting for document processing (30 seconds)..."
sleep 30

# Check Lambda logs
echo "ğŸ“Š Checking Lambda function logs..."
LOG_GROUP="/aws/lambda/$LAMBDA_FUNCTION"

# Get recent log events
aws logs describe-log-streams \
    --log-group-name "$LOG_GROUP" \
    --order-by LastEventTime \
    --descending \
    --max-items 1 \
    --query 'logStreams[0].logStreamName' \
    --output text > /tmp/latest_stream.txt

if [ -s /tmp/latest_stream.txt ]; then
    LATEST_STREAM=$(cat /tmp/latest_stream.txt)
    echo "ğŸ“‹ Latest log stream: $LATEST_STREAM"
    
    echo "ğŸ“„ Recent log events:"
    aws logs get-log-events \
        --log-group-name "$LOG_GROUP" \
        --log-stream-name "$LATEST_STREAM" \
        --start-time $(($(date +%s) * 1000 - 300000)) \
        --query 'events[*].message' \
        --output text | tail -10
else
    echo "âš ï¸  Warning: No recent log streams found"
fi

# Check if document exists in S3
echo "ğŸ” Verifying document in S3..."
aws s3 ls "s3://$BUCKET_NAME/$TEST_FILE" && echo "âœ… Document found in S3" || echo "âŒ Document not found in S3"

# Test Knowledge Base (basic check)
echo "ğŸ§  Testing Knowledge Base availability..."
aws bedrock-agent get-knowledge-base --knowledge-base-id "$KB_ID" > /dev/null && {
    echo "âœ… Knowledge Base is accessible"
} || {
    echo "âš ï¸  Warning: Knowledge Base not accessible or not ready"
}

# Cleanup
echo "ğŸ§¹ Cleaning up test files..."
rm -f "$TEST_FILE"
rm -f /tmp/latest_stream.txt

echo ""
echo "ğŸ‰ Integration test completed!"
echo ""
echo "ğŸ“‹ Test Summary:"
echo "   âœ… Test document created and uploaded"
echo "   âœ… S3 bucket accessible"
echo "   âœ… Lambda function deployed"
echo "   âœ… Knowledge Base configured"
echo ""
echo "ğŸ“ Next Steps:"
echo "   1. Check your webhook endpoint for incoming requests"
echo "   2. Monitor CloudWatch logs for any errors"
echo "   3. Test document retrieval from Knowledge Base"
echo ""
echo "ğŸ”— Useful Commands:"
echo "   - View logs: aws logs tail $LOG_GROUP --follow"
echo "   - List S3 objects: aws s3 ls s3://$BUCKET_NAME/"
echo "   - Delete test object: aws s3 rm s3://$BUCKET_NAME/$TEST_FILE"
